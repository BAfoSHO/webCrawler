# CS3640-A5

This is an open-ended project for Assignment 5 of CS3640. The goal of this project is to crawl and scrape websites to answer a specific question that we are curious about. My question: "What are differences between 1st and 3rd party cookies, and how are they displayed among different types of websites(e-commerce, entertainment, media)?"

## Getting started

This project uses ChromeDriver for Selenium testing. The ChromeDriver is automatically installed when you run the project, but you will need to install Chrome if you don't already have it. You can download Chrome [here](https://www.google.com/chrome/).

The crawler creates and uses a database to manage and store data efficiently. To ensure proper functionality, you will need database management software. If you don't already have a preferred method, the easiest to setup is DB Browser for SQLite. You can download it [here](https://sqlitebrowser.org/).


## Running the project

To get the crawler up and running, follow these steps:

1. Clone the repository to your local machine.

2. Open the project in your preferred IDE or terminal.

3. Install the dependencies listed by running the command 'install requirements.txt'.

4. Run 'python crawler.py' to start the crawler.

5. To proceed crawling, use either 'scrape' or 'research' commands as instructed by the help message. Each mode will prompt you for information to start crawling.

6. Check the repository for 'cookies.db' and open it with your database management software to view the data.


## CREDITS

